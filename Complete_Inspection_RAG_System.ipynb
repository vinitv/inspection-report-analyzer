{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Property Inspection Report Analyzer - Streamlined RAG System\n",
    "\n",
    "## Data Architecture:\n",
    "- **Knowledge Base**: `data/my-report/Rental.PDF` ‚Üí RAG system\n",
    "- **Evaluation Dataset**: `data/inspection-reports/*.pdf` ‚Üí RAGAS synthetic generation\n",
    "\n",
    "**Target Use Case**: First-time home buyers needing prioritized repair recommendations with cost estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith Project: Inspection-RAG-98e16d98\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LangSmith tracing \n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\" \n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com/\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = f\"Inspection-RAG-{uuid4().hex[0:8]}\"\n",
    "\n",
    "# Setup API keys \n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")\n",
    "\n",
    "if not os.getenv(\"COHERE_API_KEY\"):\n",
    "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key: \")    \n",
    "\n",
    "if not os.getenv(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key: \")\n",
    "\n",
    "if not os.getenv(\"REPAIR_API_KEY\"):\n",
    "    repair_key = getpass.getpass(\"Repair API Key (or press Enter for demo): \")\n",
    "    os.environ[\"REPAIR_API_KEY\"] = repair_key if repair_key.strip() else \"demo-key-2024\"\n",
    "\n",
    "if not os.getenv(\"LANGSMITH_API_KEY\"):\n",
    "    langsmith_key = getpass.getpass(\"LangSmith API Key (optional): \")\n",
    "    if langsmith_key.strip():\n",
    "        os.environ[\"LANGSMITH_API_KEY\"] = langsmith_key\n",
    "    else:\n",
    "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "print(f\"LangSmith Project: {os.environ['LANGSMITH_PROJECT']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded inspection report: 36 documents\n",
      "üìö Loaded evaluation dataset: 211 documents\n",
      "üìù Split inspection docs: 94 chunks\n",
      "üìù Split evaluation docs: 459 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the actual inspection report for RAG (following ref patterns)\n",
    "inspection_path = \"data/my-report/\"\n",
    "inspection_loader = DirectoryLoader(inspection_path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "inspection_docs = inspection_loader.load()\n",
    "\n",
    "print(f\"üìÑ Loaded inspection report: {len(inspection_docs)} documents\")\n",
    "\n",
    "# Load evaluation dataset documents for RAGAS (following ref patterns)\n",
    "eval_path = \"data/inspection-reports/\"\n",
    "eval_loader = DirectoryLoader(eval_path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "eval_docs = eval_loader.load()\n",
    "\n",
    "print(f\"üìö Loaded evaluation dataset: {len(eval_docs)} documents\")\n",
    "\n",
    "# Text splitting (following ref patterns)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "split_inspection_docs = text_splitter.split_documents(inspection_docs)\n",
    "split_eval_docs = text_splitter.split_documents(eval_docs)\n",
    "\n",
    "print(f\"üìù Split inspection docs: {len(split_inspection_docs)} chunks\")\n",
    "print(f\"üìù Split evaluation docs: {len(split_eval_docs)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector store ready\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Core components (following ref patterns)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Setup vector store (following ref patterns)\n",
    "client = QdrantClient(\":memory:\")\n",
    "sample_embedding = embeddings.embed_query(\"test\")\n",
    "embedding_dim = len(sample_embedding)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"inspection_knowledge\",\n",
    "    vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"inspection_knowledge\", \n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Add inspection documents to vector store\n",
    "_ = vector_store.add_documents(documents=split_inspection_docs)\n",
    "\n",
    "# Create retriever (following ref patterns)\n",
    "baseline_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(\"‚úÖ Vector store ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG chain ready - test response: 1663 characters\n",
      "Based on the inspection report, the HVAC system at 4319 Dixie Canyon Ave, Unit 2, Sherman Oaks, CA, has the following documented observations:\n",
      "\n",
      "**Heating System:**\n",
      "- The heating system is described as satisfactory and serviceable, with typical wear noted.\n",
      "- The thermostat is also satisfactory and serviceable, but it does not go below 65 degrees.\n",
      "- The duct system and airflow are satisfactory and serviceable, with typical wear.\n",
      "\n",
      "**Cooling System:**\n",
      "- The condensing unit is satisfactory and serviceable, with typical wear.\n",
      "- The condensate line needs attention due to deteriorated insulation. The inspector recommends consulting with a qualified specialist for further review and potential repair or replacement.\n",
      "- The temperature differential is satisfactory and serviceable, with the temperature difference between the supply air and return air across the evaporator being within an acceptable range (72-54 degrees).\n",
      "\n",
      "**Limitations:**\n",
      "- The inspection did not include checking for asbestos, system refrigerant levels, cooling or heating capacity, electronic air filters, solar equipment, programmable thermostats, or determining the remaining life of the system.\n",
      "- The inspector did not disassemble heaters, coil boxes, condensers, or air compressors to evaluate internal parts.\n",
      "- The inspection does not determine if the heater is on recall or if there is a crack in the firebox or carbon monoxide leakage.\n",
      "- Not all registers were tested for pressure flow due to location, condition, and operation constraints.\n",
      "\n",
      "Overall, the HVAC system is generally in satisfactory condition with typical wear, but attention is needed for the condensate line's insulation.\n"
     ]
    }
   ],
   "source": [
    "# RAG Chain \n",
    "RAG_TEMPLATE = \"\"\"\n",
    "You are an expert property inspection analyst helping first-time home buyers in Southern California understand their inspection report.\n",
    "\n",
    "Your role is to analyze ONLY what the inspector actually found and documented in this specific inspection report.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Use the tools provided to you to help answer the question.\n",
    "- Base all responses strictly on the inspector's actual findings in the provided context or the tools provided to you.\n",
    "- Focus on specific issues, defects, or concerns the inspector identified\n",
    "- Ignore boilerplate disclaimers, scope limitations, and general educational content\n",
    "- If the inspector didn't find or comment on something, state that clearly\n",
    "- For broad questions like \"should I buy this property,\" synthesize the overall pattern of findings\n",
    "- DO NOT speculate beyond what's documented or discuss items specifically excluded from inspection\n",
    "\n",
    "CONTEXT FROM INSPECTION REPORT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "\n",
    "\n",
    "Remember: You can only discuss what this inspector actually observed and documented. If something wasn't inspected or noted, acknowledge that limitation.\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Build RAG chain (following ref patterns)\n",
    "baseline_rag_chain = (\n",
    "    {\"context\": baseline_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Test the chain\n",
    "test_response = baseline_rag_chain.invoke(\"How is the HVAC?\")\n",
    "print(f\"‚úÖ RAG chain ready - test response: {len(test_response)} characters\")\n",
    "print(test_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 tools:\n",
      "  1. get_repair_cost_estimate - Cost estimates with smart mapping\n",
      "  2. get_available_repair_types - Live data from API\n",
      "  3. tavily_tool - Web search for additional information\n",
      "\n",
      "üß™ Testing API connectivity...\n",
      "‚úÖ Successfully fetched 48 repair types from API\n",
      "   Sample types: ['electrical_panel_replacement', 'outlet_installation', 'ceiling_fan_installation']\n"
     ]
    }
   ],
   "source": [
    "# Tools for Agent (following ref patterns)\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import requests\n",
    "from typing import Annotated\n",
    "\n",
    "# Dynamic repair type mapping using actual API data\n",
    "def get_api_repair_types():\n",
    "    \"\"\"Fetch actual repair types from API\"\"\"\n",
    "    try:\n",
    "        api_url = \"https://repair-cost-api-618596951812.us-central1.run.app/api/v1/repair-types\"\n",
    "        headers = {\"x-api-key\": os.getenv(\"REPAIR_API_KEY\", \"demo-key-2024\")}\n",
    "        \n",
    "        response = requests.get(api_url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get('repair_types', [])\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è API returned status {response.status_code}: {response.text}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error fetching repair types: {e}\")\n",
    "        return []\n",
    "\n",
    "def map_repair_type(repair_description: str) -> str:\n",
    "    \"\"\"Map user description to actual API repair type\"\"\"\n",
    "    api_repair_types = get_api_repair_types()\n",
    "    if not api_repair_types:\n",
    "        # Fallback list if API is unavailable\n",
    "        fallback_types = [\"roof_repair\", \"electrical_panel_replacement\", \"hvac_repair\", \"plumbing_repair\"]\n",
    "        desc = repair_description.lower()\n",
    "        if any(word in desc for word in ['roof', 'roofing', 'shingle']):\n",
    "            return \"roof_repair\"\n",
    "        elif any(word in desc for word in ['electrical', 'panel', 'breaker']):\n",
    "            return \"electrical_panel_replacement\"\n",
    "        elif any(word in desc for word in ['hvac', 'heating', 'ac', 'furnace']):\n",
    "            return \"hvac_repair\"\n",
    "        elif any(word in desc for word in ['plumbing', 'leak', 'pipe', 'water']):\n",
    "            return \"plumbing_repair\"\n",
    "        else:\n",
    "            return fallback_types[0]\n",
    "    \n",
    "    desc = repair_description.lower()\n",
    "    \n",
    "    # First try exact matches\n",
    "    for repair in api_repair_types:\n",
    "        repair_type = repair['repair_type']\n",
    "        if repair_type.lower() in desc or desc.replace(' ', '_') in repair_type.lower():\n",
    "            return repair_type\n",
    "    \n",
    "    # Then try keyword matching\n",
    "    for repair in api_repair_types:\n",
    "        repair_type = repair['repair_type'].lower()\n",
    "        repair_desc = repair.get('description', '').lower()\n",
    "        \n",
    "        # Check common keywords against repair type and description\n",
    "        if any(word in desc for word in ['roof', 'shingle', 'leak']) and 'roof' in repair_type:\n",
    "            return repair['repair_type']\n",
    "        elif any(word in desc for word in ['electrical', 'wiring', 'outlet', 'panel']) and 'electrical' in repair_type:\n",
    "            return repair['repair_type']\n",
    "        elif any(word in desc for word in ['hvac', 'heating', 'ac', 'furnace', 'air condition']) and any(keyword in repair_type for keyword in ['hvac', 'heating', 'ac']):\n",
    "            return repair['repair_type']\n",
    "        elif any(word in desc for word in ['plumbing', 'pipe', 'water', 'leak']) and 'plumbing' in repair_type:\n",
    "            return repair['repair_type']\n",
    "        elif any(word in desc for word in ['paint', 'painting']) and 'paint' in repair_type:\n",
    "            return repair['repair_type']\n",
    "        elif any(word in desc for word in ['flooring', 'floor', 'hardwood', 'carpet']) and any(keyword in repair_type for keyword in ['flooring', 'floor']):\n",
    "            return repair['repair_type']\n",
    "    \n",
    "    # Return first available repair type as fallback\n",
    "    return api_repair_types[0]['repair_type']\n",
    "\n",
    "@tool\n",
    "def get_repair_cost_estimate(\n",
    "    repair_type: Annotated[str, \"Type of repair (e.g., 'roof repair', 'electrical panel', 'HVAC system')\"],\n",
    "    zip_code: Annotated[str, \"ZIP code\"] = \"90210\"\n",
    ") -> str:\n",
    "    \"\"\"Get repair cost estimates using the Home Repair Cost API\"\"\"\n",
    "    try:\n",
    "        # Ensure zip_code is 5 digits\n",
    "        if len(zip_code) != 5 or not zip_code.isdigit():\n",
    "            zip_code = \"90210\"  # Default to Beverly Hills\n",
    "        \n",
    "        mapped_repair_type = map_repair_type(repair_type)\n",
    "        print(f\"üîç Mapped '{repair_type}' to '{mapped_repair_type}'\")\n",
    "        \n",
    "        api_url = f\"https://repair-cost-api-618596951812.us-central1.run.app/api/v1/repair-cost/{mapped_repair_type}\"\n",
    "        headers = {\"x-api-key\": os.getenv(\"REPAIR_API_KEY\", \"demo-key-2024\")}\n",
    "        params = {\"zip_code\": zip_code, \"scope\": \"average\"}\n",
    "        \n",
    "        print(f\"üåê Making API call to: {api_url}\")\n",
    "        print(f\"üìç Using zip_code: {zip_code}\")\n",
    "        \n",
    "        response = requests.get(api_url, headers=headers, params=params, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            cost_est = data.get('cost_estimate', {})\n",
    "            location_info = data.get('location', {})\n",
    "            details = data.get('details', {})\n",
    "            \n",
    "            result = f\"üí∞ **{repair_type.title()} Cost Estimate**\\n\"\n",
    "            result += f\"üìç Location: {location_info.get('region', 'Unknown')} (Zip: {zip_code})\\n\"\n",
    "            result += f\"üí≤ Cost Range: ${cost_est.get('low', 0):,} - ${cost_est.get('high', 0):,}\\n\"\n",
    "            result += f\"üìä Average: ${cost_est.get('average', 0):,}\\n\"\n",
    "            if details.get('description'):\n",
    "                result += f\"üìù Details: {details['description']}\\n\"\n",
    "            if details.get('labor_hours'):\n",
    "                result += f\"‚è±Ô∏è Labor: {details['labor_hours']}\\n\"\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            error_msg = f\"‚ùå API Error (Status {response.status_code})\"\n",
    "            try:\n",
    "                error_detail = response.json()\n",
    "                error_msg += f\": {error_detail}\"\n",
    "            except:\n",
    "                error_msg += f\": {response.text}\"\n",
    "            print(error_msg)\n",
    "            return f\"Cost estimate unavailable for {repair_type}. Please try using get_available_repair_types to see valid options.\"\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error getting cost estimate: {str(e)}\"\n",
    "        print(f\"‚ö†Ô∏è {error_msg}\")\n",
    "        return error_msg\n",
    "\n",
    "@tool\n",
    "def get_available_repair_types() -> str:\n",
    "    \"\"\"Get a list of all available repair types supported by the cost estimation API\"\"\"\n",
    "    try:\n",
    "        api_url = \"https://repair-cost-api-618596951812.us-central1.run.app/api/v1/repair-types\"\n",
    "        headers = {\"x-api-key\": os.getenv(\"REPAIR_API_KEY\", \"demo-key-2024\")}\n",
    "        \n",
    "        response = requests.get(api_url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            repair_types = data.get('repair_types', [])\n",
    "            categories = data.get('categories', [])\n",
    "            total_count = data.get('total_count', len(repair_types))\n",
    "            \n",
    "            result = f\"üîß Available Repair Types ({total_count} total across {len(categories)} categories):\\n\\n\"\n",
    "            \n",
    "            # Group by category\n",
    "            for category in categories:\n",
    "                category_repairs = [r for r in repair_types if r['category'] == category]\n",
    "                if category_repairs:\n",
    "                    result += f\"**{category}** ({len(category_repairs)} types):\\n\"\n",
    "                    for repair in category_repairs[:3]:  # Show first 3 per category\n",
    "                        cost_range = repair.get('average_cost_range', 'N/A')\n",
    "                        result += f\"  ‚Ä¢ {repair['repair_type']} - {cost_range}\\n\"\n",
    "                    if len(category_repairs) > 3:\n",
    "                        result += f\"  ... and {len(category_repairs) - 3} more\\n\"\n",
    "                    result += \"\\n\"\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            return \"‚ö†Ô∏è Unable to fetch repair types from API\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error fetching repair types: {e}\"\n",
    "\n",
    "# Web search tool\n",
    "tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "tools = [get_repair_cost_estimate, get_available_repair_types, tavily_tool]\n",
    "\n",
    "print(f\"Created {len(tools)} tools:\")\n",
    "print(f\"  1. get_repair_cost_estimate - Cost estimates with smart mapping\")\n",
    "print(f\"  2. get_available_repair_types - Live data from API\") \n",
    "print(f\"  3. tavily_tool - Web search for additional information\")\n",
    "\n",
    "# Test the repair mapping to ensure API connectivity\n",
    "print(\"\\nüß™ Testing API connectivity...\")\n",
    "test_repair_types = get_api_repair_types()\n",
    "if test_repair_types:\n",
    "    print(f\"‚úÖ Successfully fetched {len(test_repair_types)} repair types from API\")\n",
    "    print(f\"   Sample types: {[rt['repair_type'] for rt in test_repair_types[:3]]}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not fetch repair types - using fallback mapping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced Agent ready with intelligent tool routing:\n",
      "  üîß Cost questions: Automatic tool sequencing (repair_types ‚Üí cost_estimate)\n",
      "  üè† Inspection questions: RAG analysis\n",
      "  üåê General questions: Web search fallback\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAFNCAIAAAB+HxYwAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3WdYU2cbB/AnJGQQSBhhIwIiokBFxdk6wVFxVK1bcVZtq3XULc5XrVpLtWq11IGb2mptxVrrpA5ERUVR3KDMQEJISMjOeT8cL2opYDTn5GTcv6sfbMaTG8g/z7nPeELDMAwBAN7EgeoCALAOEBUAjAJRAcAoEBUAjAJRAcAoEBUAjMKgugAClBeqqqv01TK9Rm1QKw1Ul/NmdAaNwaA58ehOLgw3L0cnni38FWwezXqPq+Q/UOTdU+TdVwSEcVQKgxOP7ubF1Gut4MdhONLkMl21TF9dpdOqMTqdFhzJbRLNdRUwqS4N1Msqo5L/QHH1hNg7kOUdxA6O4HKt/FO5JF+Zl6OQCDUcZ0an/h5sJzrVFYE6WFlUMAN2er9QqzZ06u/h4cuiuhyC3c+QXj0hbtvbLbqrG9W1gNqsKSrlReqfvin4eGaAT2M21bWQ6PZFSWm+6sPxvlQXAv7FaqIiq9D+satkxLxAqgsxh6d35LcvSobOakR1IeAf1hGVoqfKy8dFw+fa0VvnRa7iyu/iUQvs4qPBKljBcRWVQv/HnhK7yglCqHFzbkxPt9P7SqkuBLxiBbPKieTiHiM8uTxHqguhwK0LEgaD9l5nV6oLARY/q9y+IHHzZtpnThBCrbu7Xf5NpNdZ+seZPbD0qFw9Ie7U34PqKqj0fn/BlRMiqqsAlh2VW+clXQYLHBxoVBdCpZZdXavEWoVUR3Uh9s6io5J7XeYf6kR1FdTj8hnPcxRUV2HvLDcqUpFWr8Pcfcx6WtSzZ8/69ev3Dk88cuTI8uXLSagIIYSCI7l5EBWqWW5UXj5UhLflmflFHzx4YOYnGqNxc65SrtNpreCkaRtmuVERl2g4zmSdOFhVVfX1118PHDiwc+fOU6dOPX78OEJox44dK1euLC0tjYmJOXjwIELo0qVLiYmJ8fHxH3zwwbRp027evIk/PTU1tXfv3hcvXmzXrt3GjRunTJmSlpZ28uTJmJiYhw8fklGwTovJxNCuUMlyz8lVyPSB4WRFZeXKlUKhcNGiRcHBwUeOHPnqq69CQkKmTZum0Wj++uuvtLQ0hJBKpUpMTGzXrt3KlSsRQmfPnp09e/bx48c9PDyYTKZCofjll19WrVrVokWLwMDA8ePHN27cGH8kGbg8hkKmM/PmKHidJUdFR97Z9bdu3UpISOjQoQNCaMaMGXFxca6utQ/zsdns1NRUDoeD3xUZGfnLL7/cuXMnNjaWRqOpVKpx48a1bduWpAprwaNintcCdbLcqDAcaXTSqouOjj5w4EBlZWXr1q07duzYvHnzOh+mUCi2bt2alZUlEr06siGRSGrujYiIIKu+/3Bk0zBoVShlub2KI9NBLtWTNPiKFStGjRqVkZExZ86cnj17bt++Xaer/ZldWlo6efJkrVa7du3ajIyMa9eu1XoAk2m+zSGZWOfkApd8UclyZxVSNzl4PN7EiRMnTJiQnZ194cKFXbt2ubi4jBkz5vXHnDlzRqPRrFy5ksPh1JpPzI/UzVFgDMv97bv7OmrVpGxzSKXSP//8c+DAgWw2Ozo6Ojo6+tGjR//dcyWVSnk8Hp4ThNC5c+fIKMZIXB7D2RVmFSpZ7gaYf6jTw+tVZIzMYDCSk5MXLFiQnZ0tFotPnjz58OHD6OhohFBgYKBIJLp48eKLFy+aNm0qEomOHj2q0+muXr16/fp1V1fX0tK6z4pv1KhRTk7OjRs3KioqCC+4JE+pURnYXMv9XLMH9BUrVlBdQ924PMaNMxVNo12YbILzzGQyo6Kizpw5s2fPngMHDhQUFHzyyScfffQRjUYTCAQPHjxISUlxdXUdPny4Xq8/dOjQd999J5FIlixZUl1dvX//fpFI5OnpeenSpcmTJzs4vKrNzc3t0qVLhw8fbt++fUBAALEF37ssFfiz/EI4xA4L3opFX69y7ZTYVeBo/mP2luZUSkn7Pu7uPra27IZ1sdwNMIRQy86ul3+z9/PPn9yuotFokBPKWfTmL8eZHt6Wd/uCpFX3uhf7OX78+KZNm+q8S61Ws1h1v71WrFjRrVs3Igt9TQMj63Q6BqPuX/iBAwfq22y7ekI8aLo/cQWCd2TRG2AIIb3e8Pv24kHT634baTQatVpd510qlYrNrnsNJA6HU99b1nRVVfXuimggKlwut6bted3Dm7LKcm2HD+364jYLYelRQQgJX6jSj5UPm21fy1AghIQvVem/lA+bY3c/uGWy6F4F592YHdGRdyqlhOpCzEqvw45+Vwg5sRxWMKvgCh5V52RI7WTNxQqh5tiWwgkrgukMu75Y2qJYTVQQQo9uVt06LxkyM4DJsoLJ8J3l5civnhCPXBBo54sKWBprigpCSFSsvvhzmV8Ip1N/AdW1EK8kX3n1hNjTn9VlsCfVtYDarCwquKxzkow0cYe+7v6hHN9gqz+GrVEZ8u4rSl+oyl+qO/X38Gti9T+RTbLKqODupEue3lFUlmladOQhDHF5DJ6Ho1X8MDQHpJLrFVKdQqavrtK9fFgdHMENa+MS1IJLdWmgXlYcFZxSoS98XC2r0ClkOkyP5ESvl/X06VNPT08+n0/gmCyOA75kEZdH9/Bh+jeFBZysgNVHhWyzZs0aMmRI586dqS4EUMyWdyUBQCCICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSIyhu4urrS6fAt2ACi8iaVlZV6vZ7qKgD1ICoAGAWiAoBRICoAGAWiAoBRICoAGAWiAoBRICoAGAWiAoBRICoAGAWiAoBRICoAGAWiAoBRICoAGAWiAoBRICoAGIWGYRjVNViiuLg4NpuNEJJIJE5OTiwWCyHEZDKPHTtGdWmAGgyqC7BQAoHg6dOn+L/VajVCCMOwMWPGUF0XoAxsgNVt4MCBTCbz9Vv8/f1Hjx5NXUWAYhCVun300UeBgYGv39KtWzcvLy/qKgIUg6jUjcPhDBgwgMF4tYHaqFGjhIQEqosCVIKo1Gvw4MH4xEKj0eLi4gQCAdUVASpBVOrFZrP79+9Pp9MDAwOHDRtGdTmAYrawB0yp0IuLNRq1gfCR20X2jwh+0Lp16yqhU5VQQezgNIRc3Bhu3kw6g0bsyIAM1n1cRa/D/tovLHxSHdCMq1URHxVSsbh0cZGK5oBatOe17OJKdTngDaw4Kmql/uiWora9BT5BTlTXYpKrvws9fJkxcW5UFwIaYsW9yk/fFHb92Mfac4IQ6jTAW1yizU6vpLoQ0BBrjUrOVWnIe848D6YRj7UCnQZ45d6o0uusdYa3B9YaFeFLNcfFFvZJ1DDoMYlQQ3UVoF7WGhWtysB3t5EpBSfwY8sqdFRXAeplrVFRVuv1VrbH6w3USlhv36JZa1QAMDOICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagAYBSICgBGgagQLy/v2YhR/aiuAhAMokK8R48fUF0CIJ5NXR3VsIyMS+cvnL5777ZMJm0eHjl27ORW0TH4XQ8e3Nu0eV1h0cuoqFYJYybvSN4cEhw6e9YihND9+3f37kt++PA+39WtY4fO4xKmcLlchNCvx4/sP7BzU1Ly8pXz8/Ofh4SEDv14dJ/e/fek7Ni3fydCqHtszNLEtT2696L65wbEsJdZRaVSrfkqUa1WL1ywcu2aTYGBQUsSZ1dUiPG7FifOdnNz373zyKSJn23bnlReLqTRaAihwqKCufM/U6lVW7fs+d/Kjc+fP5k9Z4pOp0MIOTo6yuVV323ZMO/LpefP3ujaJW7D16uEwtIJ46eNGJ7g7e1z4dxNyIktsZeosNnsncmpX85Z0io6plV0zLSps5RK5b2cOwiha5mXpdLKqVNm+vj4hjUN/2TydKGwFH/W2bOnHBmO/1u5MTAwKCgoZO6XS588fXT5ykX8Xq1WOy5hSosWUTQarXevfhiGPX36iNKfEpDIjjbAqqsVO3dtvZOdJRaL8FsqKyUIoby8p87OziEhofiNraJjXFx4+L/v388OD4/g818t0uXj4+vnF3D33u1uXePwW8LDI/B/4E+Ry6vM/mMBM7GXqAiFpTNnT27dqt3SJWvxeaBn7w74XVXyKicn7usPdnV9tSSXXF718NGD7rExr98rqRDX/BvfTgP2wF6icjH9jEajWbhgJYfDqZlPcGwWW6P511IpYnE5/g93D0FUVPSE8dNev5fPg5Ug7ZG9REUmk7q48PCcIITS/z5Xc5e/f6PKSklFhdjd3QMhdPvOzerqavyuJiFN/zpzsuV7rR0cXjV1+fnPAwIC63oFYOPspa0PCWkqFot+P3FUp9NlXr9669Z1Pt+1rKwUIdSh/Qd0On3L1q8VCkVhUcH+/Ts9PV995dDHH482GAxbv/9GpVIVFLz4Ifm7iZOHP8972vBrBQQEisWiy5cv1uweADbAXqIS26P32DGT9u3/sWfvDkePHvpixvyecX0PHU5J+nath4dg9qxF2XdvDRnaa/2GFaNGTeBwnBgMR4QQz4W3a+dPHDZn6qdjEsYPuZOdNW/u0rCm4Q2/Vof2H0RFRi9dPjfrVqa5fj5AOmtd3vvX74tadHT3C+EQMlpRcaGLC4/nwsO/HrXfgK4Tx386ZMhIQgY30sWfSiI68kKiuEY8FlDAXnqVBkillZ99Pi60SdikSZ+7ubnv2rXNgebQrVtPqusClsVeNsAawOe7rlu7GcOwZcvnTp06uqpKtm1riocHfJ0d+BeYVRBCqHnzyKRvdlBdBbBoMKsAYBSICgBGgagAYBSICgBGgagAYBSICgBGgahYCus8a8KOQFQsBYaw9evX37lzh+pCQN0gKpbCgUabMGFCfn4+QigrK4vqckBtEBUL4uXl9dFHHyGEKisr33//faFQSHVF4B/WGhWewBEhm9q65zgzGI6vLj+OjY09d+4cftL3jh07ai41AxSy1qhwnOiiIhXVVRDpRa7cw49Z879sNtvHxwch5OLi8sknn+CLMFFaoL2z1qgEtXCSlmuMeKB1qCzXeDdmcXl1nL06evTogwcPIoSuX7++ZMmSyspKKgoEVhsVvxCOhy8z40QZ1YUQwKDHLqaWdPvYq+GHdenSpXPnzunp6QghvPsH5mStV0Hibp4VC19q/Zo4CfzZDEdriz0NVVVoqiq0106Wj18WxOW/xQURSUlJubm527dvZzDgMgozseKopKenX7t2bcTA6Y+z5Eq5XlL6hu0xA4apVConjknXGGu0WjqdTncgIJZcV4YDnebXhN3hQ493ePqtW7fCwsI0Gk1WVlbPnnDNJumsOCpz5sxJSkoy5pEqlWrbtm2nT58uLy///PPPJ0+e/M4vunXrVi6XO2HChHcegVg6nS4xMdHZ2TkxMZHqWmyc9UWlsrIyKysrNjbWyMenpqampqYWFhYihJhM5vLly3v37v3Or15WViYUCqOiot55BDKIRCKBQHDo0CEMw0aPHk11ObbJyrbvZTLZkCFDYmJijHgsSk9PHzdu3JYtW/CcIIS4XK5AYNJF815eXpaWE4QQ/kMNHjxYKBT+/fff+GxDdVG2xppmldLSUp1OFxAQYOTje/XqJRKJHF7rKzw9PX/44YfAQJOWh1y4cOHSpUvxb1mxQBiG0Wi0wYMHx8XFffbZZ1SXYzusY1aprq4eOHAgh8MxPif45latW+h0ure3t4nFKBSK7OxsEwchD77i+LFjxzw9PfHdygUFBVQXZQusY1ZJS0uLjo5+q5zU6Nixo1arxT9uo6KiUlJSTCymuLiYRqP5+vqaOI55iESiyZMnT5kypW/fvlTXYt0sfVZZtWoVQqhfv37vlpPy8nI+nx8QEIBhGIZhHh7vslu2Fj8/P2vJCd7GHD9+PDQ0FCG0b98+OGf5nVl0VJKSktq1a2fKCPPnz9+wYcPx48ezsrI4HI7pW18IoYqKipkzZ5o+jjmFhYXhE2xycnJhYaHBYKC6IiuEWaQLFy5gGCaVSk0ZZP/+/UlJScQV9Y/Y2NiKigoyRjYDpVKp1WqHDRuWkZFBdS3WxBJnlaSkpKKiIoQQj8d750GKi4t/+umn2bNnE1raK/v372exWGSMbAZsNpvBYKxZswbfOZGXl0d1RVaC6qz+S3l5OYZhV65cMX2o0aNHP3jwgIiibNytW7e6du368OFDqguxdBY0qxw8ePD06dMIoU6dOpk41J49ezp06NC8eXOCSqvtxo0b+P4GG9CqVasTJ07gOwmPHj0KV8XUx1KiolQqhUIhISdlvHz58vfff58+fToRddUtKCjo6tWr5I1vZi4uLpGRkQghBoMRGxtrMBjgYP9/UX9cJTs7u6KionPnzkSdTz58+PA1a9bgu0fJI5FI+Hy+AxGnGFsaDMNevHixe/fuL774wsTzgGwJxX/p4uLizZs3d+3alaicJCcn9+jRg+ycIITc3NxsMif48f6goKD27dsfPnwYP5+I6oosApWzilgsViqV73ZssU7Pnj1btGjRkSNHiBqwAbt376bRaJZzNj55Dh48eOnSpQ0bNpiyQ9IGUPO5WFJS0rZtW2dnZwJzUnPAkcABGxAWFmYny9uNHj160qRJ+EpLly5dorocylAzq/zxxx99+vQhdgNm27ZtHA5n4sSJBI7ZML1eT6fTzfZylmDZsmUVFRVbt26luhAqmHPPtFqt/uKLL8gYOTc3d9SoUWSM3AC1Wm3mV7QEBQUFGIZdvnw5NTWV6lrMyqwbYImJiZ9++ikZI5tz06vGwoUL8fVT7Aq+zRwTE/PixYu9e/cihOzkjDIzbYCdOHGif//+JA2+adMmDw+PsWPHkjR+ffbu3Yth2Pjx4838upZDp9MxGIw5c+YEBQXNmDEDv1TGVpljVvn888/J23mSk5Nz+/Zt8+cEITRu3Dh7zgl+yBI/Z4/P50skErlcXlJSQnVRpCF18y4vLw/DsCdPnpD3En369BEKheSN3wC9Xo+ftAZwSqUyPj4+JSWF6kJIQeKssn79+mfPniGEyDsguHHjxoSEBC+vN6zLSBIHB4eEhARYr74Gm81OS0vDz5E5e/asjS2BSVZUysvLg4KCjF+C6B3k5OTIZLKRI0eS9xJvNHDgQPx6AVCjTZs2+HGnVatWFRcXU10OYchq6/GGj4yRa8yZM2fgwIFdu3Yl9VXAO6uurmaxWDZz6ImsWUUsFm/evJmkwfELkl6+fEl5TkQiEZy1Xh8nJyebyQmJUfH29j58+DB+FQQZ9uzZYwnnX61evfrGjRtUV2Ghpk2b9ujRI6qrIAyJbf327duVSiUZI5eVld24cSM+Pp6Mwd+Kp6cnx7T1wm2YQqHQ6/VUV0EY6q9XeQfr168PDg4eNmwY1YWAhkCvYqxr167t37+f8GEVCsXJkyctJCfQqzQAehVjCQSCtLQ0woe1kC4FB71KA2ysVyFxf25oaOjixYvx1aYJHDYlJeXmzZsEDmgK6FUaAL0Klfbs2aNQKEhdYgIQxcZ6FXKjsm/fPi8vrz59+hA1YJcuXU6dOmU5X9ggEomcnZ3ZbDbVhQDSkXtmsYeHB4GLAB05ciQ+Pt5ycgK9SsOgV3kLvXr1io6OJmq0PXv24NcSWQ7oVRoAvQo1Tp48mZmZaTNrOtoDG+tVSL+0a968effv3zd9HIvaR1wDjqs0AI6rvB1fX1/TFwFKT08PDAwMDg4mqCjCQK/SAOhV3s6MGTNMP2ly9+7d8+bNI6giIkGv0gDoVd5av379MAyTyWRyufz27dtv+/QbN27s2rVrx44d5FQHCDZ06FAGg8FgMAwGA36pLYPBYDKZu3btoro0k5A1q0yaNCknJ0ev179+tF4gEGRlZeFXyRnPMrsUHBxX+S+FQlFWVvb6LQaDgZJ1QohFVq+ya9cuPz+/mu+GxrHZ7JYtW77VOA8ePKiqqmrfvj0JNRIAepX/iomJqbXd1ahRI0K+DoRaJLb106dPd3V1rflfg8EQGRn5tlcRW/KUAr1KnRISEvBPyRrdu3enaqkQApEYldjY2H79+tVkg8FgvO3k8OLFi2fPnvXo0YOcAgmwZMmSmJgYqquwLKGhoa//Tvz9/UeMGEFpRcQgd2fxrFmzWrVqhS/U6ebmFhER8VZPt/ApBY6r1CchIaHme8+7devm4+NDdUUEIP24ynfffRcYGGgwGFxdXZs2bWr8E0UiUUZGBnnLtxICepU6NWnSBJ9YfH19R40aRXU5xDCqc9BpDUr5Oy/hTFuyYPXy5ctbv/d+leQtvmEwZedPCaOmGvkUzIDxPBzftcJ3R1WvolLotRqLPiNpyMAxt67nxnWLc2J6vNXf3cwwA+J5GJWCNxxXyb0uu3tJWlGqcXI26xkKGEI6nc7R6H0Azu6OJc+VwZHc1j1cfYNtuc/O/FOcm1nFcaar5LZzdI9Cbr7M4qfKJi2dO/R1d3Fr6NO2oahc/6tCVKyN7uru4k7BB/bbwjBMWq69/JuwU7xH4+ZO5nlRcx5XwTAs7cdSr0B2YAtnZ74V/EWshU5rkJSpL6SWDp7h7+bJrO9h9fYqmX9WSMt1nQd5W0VO8AM4rl7Mfp80yvyz4kVutXle1Jy9yokfS/zDuC06ukFOiMVwdPD05wz7MvjYd0Xyynq3FeuOiqRMIypSd+hnlfvCY0f73r4gMc9rma1XeXpHzvNgNm1l119cSrbuI30yTorru7fuqIiK1BhmrV8rw2TRK8u1sgqyFrZ8ndmOqwhfqlgc2zmh3TK5erKeZcvru7fuqMiles9GVnxeU6NmXEmZOaJituMqGpXB3YdlhheyZ45MB/9QJ5m47ndO3VHRqg1alRV/wZ+8UovpzbEv1Wy9iqJSZ9BZ9N5h2yAuVaN61uKi5nvrbQacA2Y/SL+0y7YtWbKE6hKAmcCsYhI4B8x+QFRMAueA2Q+IikmgV7Ef0KuYBHoV+wGzikmgV7EfEBWTQK9iPyAqJoFexX5Ar2IS6FXsB8wqJoFexX5YUFRWrFwwd95nVFfxdqBXIcrRY6lxvd5xtbeBg2L37d9JdEW1ERaVX48f+Wr9cqJGsxbQq1iC4cPGvhfViuxXIaxXefToAVFDWRHoVSzBqJHjzfAqxERl1pwp2dm3EEJ//XXyhx0HwpqGv3yZv2nzusdPcul0RlBQyPhxU1tFv7oE6sqV9L37kl+8zOPzXUNDm82cscDbu/Y6Udcyr/z0076Hj+67uwsiI1tOmTzDw0NASKnEstg1i58/fzrpkxFfrdm0MWm1q6vbzuTDcrn8518OXL+RkZ//zMNd0KlT14kTPsUrl0gqvlq37P6Du4GNggYOHFpY+PLS5Qt79/zS8EtkZFw6f+H03Xu3ZTJp8/DIsWMn43/ivLxnEycP/37b3kOH9ly+ctHT06t7t15TPpmBf9fKsV9/unbtUm5uDpPFavle60mTPvf3C3h92JmzP2ExWRvWb625ZemyueIK0fdbU16+zN+TsuNOdhaGYRER740YlhAVFY1vgA0ZPDJh7GRS3znEbIBtSkpu3jyyV6/4C+duhjUNl0gqps+Y4OXlk/zDoW1b9ri5uv9v9eLq6mqE0M2szGUr5vXqFX8k9Y/lS9cJhSWbvltXa7THTx4uWjyzVau2Kbt/+WLG/GfPHq/fsIKQOglnsb2Ko6MjQmjfgZ3Dh439ck4iQujYr6mHDqcMHzZ27ZpNU6fOvJh+Zu++ZPzBGzauelmQ//WG71f/Lykz80pm5hUHhze8MVQq1ZqvEtVq9cIFK9eu2RQYGLQkcXZFhbjmpb9JWh0b2+evPzOWLFp95OcDFy6eQQjdu3dny9avIyJarlq1ceGClRJJxZq1ibVG7ttnYNat6/hQ+Atdy7zcq2e8RqOZNWcKnU5fv27LN19vZ9AZSxJn19qnQuo7h5SdxT//cpDJYs39MhFfhXXe3GUfD+v92+8/jxwxbvee7V069/h4yCiEEJ/v+tmnc+bO++zhowfhzVrUPD3n3h02mz1m9EQHBwdvb5/wZi2e5z0lo07TWWyvgq+q3jamw9CPX62rPWzomK5dYhs3fvV1Tjk52ddvXJ065QuptPLatcszps9r0TwSIfTlnMSRo/oJPN+wrAKbzd6ZnMrhcPh8V4RQ8/DI337/5V7Ona5dYvEHdO0S161rHEKoZcvWfr7+jx/nxsX2adEias+uIwEBgfgbQ6fVLk6cLZVJ+Tx+zcjdu/fa+v3G8xdO42+Sy1cuIoR69OhdUPBCIqkYMnhkWNNwhNDyZeuy797S6f61agSp7xxSovI872nTpuE1qxVzudxGAY0fP85FCD1//qTmt4kQahbWAiH08OH916MSGRWtUqkWLZkV06Z9x45dAvwb1Wy8WRoL71XCmjav+bejo+ONmxnr1i9/+uwx/g5zc3NHCD17/gQhFBn56hsKnJ2dW7du97Ig/42DV1crdu7aeic7SywW4bdUVv6z+kdY2D8v7ezsIpdXIYTodHpxceG277/JfZijUChePUtS8XpUmExmXOyHZ8+ewqNy6dL59zt15bnwWEyWq6vbug0resb1jW7ZJjKy5X/fFaS+c0jZWVwhFrFZ/9p8Z3M41cpquVyuVqtZr93l5OSE/9Jff3BY0/B1X30n8PBM/nHL2IRBc+d9lpOTTUadprPw4ypM1j+X4yf/uGXv3uT4+EEH9h2/cO7m6FGvFoOuqpIhhLhc55pH8l5749ZHKCydOXuyVqtdumTtX39mnDl9rdYD6tyEu3IlfcnSOc2atdiU9OP5szdeb0he1y9+8KPHuUXFhSqVKvP6lZ5xfRFCLBZr87c/dmj/wS9HD82YOWn02I/OnPmj1hNJfeeQEhUnLlel/tcbSFld7eEuwJtIlUpZc7uiWoEQ8nCv3Xi1b9dp3tylhw9GyC4hAAARCUlEQVSeWDh/hUwmXbxkVq2p1kJYbK9SC4ZhJ9KODho0vF/8IHwnCv4xjxDCP7m0Gk3NgyWVFW8c8GL6GY1Gs3DBypYtWzs6OtaM1rC0P36NioqePOnz0NAwGo1W37OaNGnavHnkqVO/ZV6/wuE4tW//Pn57YGDQp9NmpR5KW/O/pJDg0LXrlj1+8rDWc//7ziHqS/ZIiUqzsBa5uTk1XwEpq5K9eJkXHNyEwWA0C2t+//7dmkfi/w5p8q9lv+/cycq8fhUhJBB49u7d7/PPvqySV5UKS8go1UQW26vUotVqlUqlQPCqA9FoNFcz/sb/3ahRY4RQXv4z/H/lcvmtW9ffOKBMJnVx4dX87Ol/nzOmDJlM6in4pwu6dOl8fY/s++HAi+lnL1z4Ky72Q3xL/uXL/FN//o63SZ06dVmxfD2DwcC36mvU+c4RicqNqe2NCIuKv3+j3NycW7dvSCQV/fsPUSjk3yStEQpL8/Off7VuGZvF7vvhRwihQR8Nv3zl4tGjh2VVstt3bn6/Pal1q7ZNQ5u9PlTO/ewVK+efSDtWWSl5kJtz7NdUgcDTx9uXqFIJZC3fr8JkMgMDg079+XtRcaFUWrlh46qoyOiqKplCofD3C2jcOHjvvuSi4kK5XL5p81e+vv5vHDAkpKlYLPr9xFGdTpd5/eqtW9f5fNeystKGnxXaJOzGzWu379zU6XQ//3IQv7HOD8Ee3XuLxeWZ16/0/XAgfotMJt3w9artOzYVFhUUFLw4eGiPTqeLjPjXl8DV+c4RCDzf5ldVL8La+v7xgx8/zp03//P167bEtGm/fNm6/ft3jhjVj893bd48cvOmnVwuFyHUq1d8uajsp5/3b/3+G29vn5g2HT6ZPL3WUMOGjqmslGzdtjHp27VMJrNH997fJiW/7dd9mYfFHlf5r6VL1m77/pvxEz5ms9mffTonOjrm+vWrg4bE7U05On/uso1Jq8cmDGoS0rRnz75crnNubk7Do8X26P3ixfN9+3/8dtNXbWM6LJi/IvWnfYcOp1RVyYYNHVPfsyZO/Ky6WpG4dI5SqRw8aMTCBStLSooWLvpiyeLVtR7p5OTUpk378jJhcHAT/JbIyJZzZi9O2fvDkZ8PIIRi2rRP+mZHUFDI68+q852DH88xXd3Le18/XaFRoZbd3Al5DfM7f7i4ZWd+UASX7BeaNWvWkCFDOnfuTPYLpSUXN4nmBzQj5SeSSitVKlXNgeBFS2Yx6Iz/rdpIxmsZSaPRDB3+4ZRPZsT3/cicr3t0c/7g6QE89zo+ly3xo9qKWEuv0rCVqxaWlhZ/+uns96Ja/X7iaFZW5prV31JVTGlpSVFxwbFfUxs3Dq7Z+rIEEBWTWPhxFSMtX77+642rfty5tbxc2DgwePnSdW1jOty7d2fxkln1PeXA/uP4wUfCnTv/585d28LDI1YsW0+rZ6FHSkBUTGJFvUoD+Dz+6lXf1LoxKio6OflQvU8hJycIodGjJtQc87EoEBWTrF692jy9CiV8ffyMeJS9sKBLu6yRbfQqwBgwq5jENnoVYAyYVUxi4eeAAQJBVExiLeeAAdNBVEwCvYr9gF7FJNCr2A+YVUwCvYr9gKiYBHoV+wFRMQn0Kvaj7l6FyaYZkAWdfvO2uK6ODnRz1G+2XoXr5ugAfSX5PHzr/cbzumcVFzfH8hfKOu+yCi9z5e4+TDO8kNl6FTbHQVysNsML2TONSl/8TFnnGfj1RsWrEcuSzul8O0q5TuDPcnY1x4ew2XoVnyCWWknMNeKgPhVCddNWzvXdW++s4h/K/vvoG67/tExnDxS37elmntcyW68SHOmsVurvXX7zAhHgnZ07WPzBwHqXoqz7Kkjc/Qzpkzvyll093LyZdIal7wBQVetlIs2V38r6JHh7BVr3WfH1OXtYyGIzAls4u/vUu0kN3pZCpqss11w4XDJuaWMnXr0bIw1FBSGUd19xJ72yNE9Fd7ToDTK+h6OsQhvUghvT083NyxxdCs7816tk/135IFNm0CFFlSWu9vQ6g8FAozlY+Ja8VwBbUqYOiXJ+v78Hg9nQfPCGqNRQKw3ElUc8zIDYXArmPbNdW18LZkAatUX/RRBCU6dOnT17dnh4ONWFNAQzYGyuUetUGNv7sjiWvgFGCaqOq9AcrOAvosdUjiwrqNNIsK/eJHAOmP2wkcRTBc4Bsx8QFZPAOWD2A6JiEjgHzH5Ar2IS6FXsB8wqJoFexX5AVEwCvYr9gKiYBHoV+wG9ikmgV7EfMKuYBHoV+wFRMQn0KvYDomIS6FXsB/QqJoFexX7ArGIS6FXsB0TFJNCr2A+IikmgV7Ef0KuYBHoV+wGzikmgV7EfEBWTQK9iPyAqJoFexX5Ar2IS6FXsB8wqJiksLIRexU5AVEzy559/njt3juoqLBSXy3V3d6e6CsJAVEwyefLk/Px8qquwRAMGDJg3b56Pjw/VhRDG2NUlQcN+/fXXQYMGUV2FRRCJRPHx8ceOHfP396e6FiLBrEIMFxeXH374geoqqHf//v3Ro0dfuXLFxnICe8AIExcXx+fzqa6CYufPn09JSTl9+jTVhZACZhXCtG3bFiG0ePFiqguhxuHDh0+dOrVv3z6qCyELRIVgc+bMmTZtGtVVmNu3335bVFT09ddfU10IiaCtJ57BYHBwcMjLywsODqa6FnNYuHBhZGTkmDFjqC6EXDCrEM/BwQEhlJqampWVRXUtpJs4cWJsbKzN5wSiQqJFixbdvHmT6irIFR8fP3PmzJ49e1JdiDnABhjpfv7556FDh1JdBcGEQmF8fHxaWpotHWRsGMwqpOPxeLt27aK6CiLdvXt3woQJN2/etJ+cwHEVc+jdu7ctNS1nzpw5dOjQH3/8QXUh5gazijm0adMGITR37lyDwdK/67RhBw4cOHfu3J49e6guhALQq5hPZWVlYmLi1q1bqS7kHW3cuJFOp8+ePZvqQqgBUaHAo0ePmjVrRnUVb2fevHmtW7ceOXIk1YVQBjbAKPDbb79ZV/eSkJDw4Ycf2nNOICrUmD9/fk5OTq0bhwwZQlE5DdHr9b17916wYEGPHj2oroViEBVqjBs3Du+Sa2559uzZunXrKC0KFRYW9u/fPzY2Fv/f4uLijh07Hjx4MCIigtrCLAFEhUq+vr7JyckIodatWzMYjMzMTGqv1D99+nRJSYlUKu3Tp8/t27enTp16/fp1gUBAYUmWA9p6it27d2/SpEn4TmQWizV37lwKr6YcMWLEkydPaDQaQohOp2dmZlJViQWCWYViU6ZMqTnYolQq09LSqKrk8uXLxcXFeE7wLmXAgAFUFWOBICpUGjBggFarrflfBweHkpKS+/fvU1LMsWPHFArF67cUFxf379+fkmIsEESFSgaDgcPhGAyGmolFKBQeP37c/JUUFRU9ffoUn1IwDDMYDGw2OyAgwJZWJzIRnANGpbS0tMzMzJs3b2ZnZ+P9tFwuv3btmkKh4HK55qzkxIkThYWFTCbT09PT2dk5LCysXbt2ERERQUFB5izDkkFbb25SkfZptrwkXy2X6JQKPceFUVmmRgghDBkwA2bADAaDI9PRzFVptVoaotEcaA4ODjXtCtuJznCkcZwZngGsxuHsxs3Nml5LA1Exn1vnK+9dkWo1GNfDycmVzWDS8f+orqtemB7TanQ6tV6v1cuEiiqRMiyG16aHq7sPk+rSKABRMYecDNnVE2K+jzPf15ntbK3vM8yAVYmry59KvBuzug7xcHE199RHLYgKubQadHx7sUbr4BXq5siykc6wsliuEMvf68yP6uhMdS3mA1EhkUZl2Pu/Fz7hAheBE9W1EK8guzT0PU7HvvayiwyiQhZVtf7nzcU+4V6ObBuZTP6r5EF583ZO0Z15VBdiDnBchSwpK/P9InxsOCcIId8Wng+zlLcuSKguxBwgKqRI/aawUUsfuqPt/3p9mglyrilePqqmuhDS2f7f0vxunq1w5LK5bmyqCzGTRu/5nDtcbjDY+JY8RIVgBgN27Y8Kj8ZuVBdiPjQHmosXN+NkBdWFkAuiQrC/fxX5hNnLTqEagmC37PRKnca616NpGESFSJgBe5JVJWhsuV+08vWWkUdPbCBjZEEw/056JRkjWwiICpFePKxm81hUV0ENZw+nx7cURjzQWkFUiPTktoLrYYNHG43hxGfJpTqFTEd1IWSx5b3+5icV61wCyDoep9frTp3dkfv4SmVlaXDjlp3aD23R7H2EUInw2TdbR30xdff5v/fm5KbzeV7RUT379vycTqcjhErLnqceXSUszwsNaRPXdSJJteHcA7hFz5RhrVxIfRWqwKxCpPICpSNpZwr/mrbxUsbhD9oPXfzl8aiIHvtSF97NOY8QYtAdEUI///ZVq/d6r1t+edTHK9OvHMy+fxYhpNNpd+6b5cr3mv/FT/G9pl+8fKCqSkRSeQghvY4ml9jsrAJRIYxGZUA05EAn5Veq1apv3jnZo/O4ju0Gc5347dsMaPVe7zMX/1lgv2VEj5aRsQyGY5Pg1h5u/oVFDxFC9x5cqJQKB3w4283Vx8crZFC/uUpVFRnl4ehMulwKUQFvIpdq3Xw5JA1eUJyr02nCQtvX3NIkqHWJ8KmiWor/b4Bf85q72GwXPBIicQHTke3u5ovfznMRuPK9SaoQIcTkMPQ2mxToVYjDdqLLylQ+4aQMrlLKEULbdk6pdXuVXEx3YCCEaLQ6PvWqlTIm61+7GRwZJJ5DoFXrDSybPWYPUSGMkwtDozJgGFZzwS2BeDwBQujjgYsE7o1ev92N7yOrv/1w4vDU6n+dnaVSk7g/V6fWu7hZ7kWdJoKoEInjwtCp9WScTezpEejoyEIIhYa0wW+pkldgGMZiOaH6uw83V1+tVlUifOrrHYoQKip5LKsqJ7y2GnqtjssnaxOUctCrEEngx1LK1GSMzGI59er+yZkLu56/uKPVae7mnE9OmXEs7Q3H3SOad2EwmD8f/0qjUUll5QeOJDo5kXgmgbpK493IZk8ShVmFSE2jnbKvVvO8SFnZpHvnsX6+YRcu7Xvy7Aab7RzUKGrowMUNP4XDdp40JunkX1sT1/RgOrLje02/dfc08VuHCCGENEqdQW8Q+NvsyQpwFSSRlHL9vjUvmnVpTHUhFBC/lLq76boP86K6ELLABhiROM50vyacKpGS6kIooJQqIzrZ8pXDsAFGsE7x7r/9UOoiCKjvAYlrYuu83WDQ02gO9e09WzjrqDPXlagid+2fk/cyu867nDi8aqWszrtWLzlX34DSUgXP1cErwGYbFdgAI8Ufe0o1Bo6rX90L/1RIit9hTHc3P5Pr+odMJtLpNXXepVYrWay692I1UMPTqwVDZ/nzPWx5ZTCICvEMBmz3ivzQjoFUF2ImkoJKv0Ba+z42fkEb9CrEc3CgfTTNL+9GEdWFmINMKGcgjc3nBKJCFoEfq8dQj6IcIdWFkEtWptBXV/ef4kt1IeYAUSFL4+bczgNc8213bqkskinKpIM+s4ucQK9CuvJC9a/birybCfjetvONC3qtXlIk4/P0PUeTeJ6ypYGokM6gM6TtFopLtV5N3Lnu1n2KFGbAyp5JKourOg8StGhvy0dR/guiYiZlBaqraRJRkZorcHLxdHLis0i6CIwMWpVOVl6tEFczGFjTlty2vexolbMaEBWzkom1z+8pHt+WS0UavRZjchguArZKrjXiqdRQybXqar13kJObNyMs2jkw3E4X2YCoUAbDMI3KUC3TKxV6zFIXmmMwHbg8OpdHpzmQdI6lNYGoAGAUq9lcBoBaEBUAjAJRAcAoEBUAjAJRAcAoEBUAjPJ/xpYC0Lg7kw8AAAAASUVORK5CYII=",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x17da22090>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Enhanced Agent with Smart Tool Routing\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    question: str\n",
    "\n",
    "# Create tool-enabled LLM with enhanced prompt for smart routing\n",
    "enhanced_tool_prompt = \"\"\"You are an intelligent property inspection assistant with access to specialized tools. \n",
    "\n",
    "INTELLIGENT TOOL USAGE STRATEGY:\n",
    "\n",
    " For SIMPLE COST questions (\"How much does X cost?\"):\n",
    "  1. FIRST call \"get_available_repair_types\" to see available categories\n",
    "  2. THEN call \"get_repair_cost_estimate\" with the appropriate repair type\n",
    "\n",
    " For COMPLEX BUDGET/PRIORITIZATION questions (\"What should I prioritize with $X budget?\"):\n",
    "  1. ANALYZE the inspection document for findings and issues\n",
    "  2. IDENTIFY specific repairs mentioned in the inspection \n",
    "  3. GET cost estimates for those specific repairs using repair tools\n",
    "  4. PRIORITIZE based on safety, urgency, and budget constraints\n",
    "\n",
    " For INSPECTION FINDINGS questions (\"What issues were found?\"):\n",
    "  - Analyze the inspection document content directly\n",
    "\n",
    " For GENERAL questions or when repair tools fail:\n",
    "  - Use \"tavily_tool\" for web search\n",
    "\n",
    "EXAMPLES:\n",
    "- \"How much does roof repair cost?\" ‚Üí get_available_repair_types ‚Üí get_repair_cost_estimate  \n",
    "- \"What should I prioritize with $5000?\" ‚Üí Analyze inspection findings ‚Üí Get costs for specific issues ‚Üí Prioritize recommendations\n",
    "- \"What HVAC issues were found?\" ‚Üí Analyze inspection document\n",
    "- \"Latest home inspection trends\" ‚Üí tavily_tool\n",
    "\n",
    "ALWAYS explain your reasoning and show your thought process when using multiple tools or analysis steps.\"\"\"\n",
    "\n",
    "# Enhanced LLM with routing instructions\n",
    "enhanced_tool_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1).bind_tools(tools)\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"Enhanced agent node with intelligent tool routing\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Add the routing instructions as system context\n",
    "    if not messages or not isinstance(messages[0], HumanMessage):\n",
    "        system_context = f\"{enhanced_tool_prompt}\\n\\nUser question: {state['question']}\"\n",
    "        enhanced_messages = [HumanMessage(content=system_context)] + messages\n",
    "    else:\n",
    "        enhanced_messages = messages\n",
    "    \n",
    "    response = enhanced_tool_llm.invoke(enhanced_messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"rag_analysis\", END]:\n",
    "    \"\"\"Smart conditional routing - handle both simple and complex questions\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    question = state.get(\"question\", \"\")\n",
    "    \n",
    "    # PRIORITY 1: Check for tool calls first (LLM decided to use tools)\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # PRIORITY 2: Complex budget/prioritization questions need RAG + tools\n",
    "    complex_budget_keywords = ['prioritize', 'priority', 'most important', 'urgent', 'critical']\n",
    "    cost_keywords = ['cost', 'price', 'estimate', 'budget', 'expensive', 'cheap', 'money', 'dollar', '$']\n",
    "    \n",
    "    has_budget_context = any(keyword in question.lower() for keyword in cost_keywords)\n",
    "    has_prioritization = any(keyword in question.lower() for keyword in complex_budget_keywords)\n",
    "    \n",
    "    if has_budget_context and has_prioritization:\n",
    "        # Complex questions: \"What should I prioritize with $5000?\" - need inspection analysis\n",
    "        return \"rag_analysis\"\n",
    "    elif has_budget_context:\n",
    "        # Simple cost questions: \"How much does X cost?\" - should have used tools already\n",
    "        return END\n",
    "    \n",
    "    # PRIORITY 3: Check for inspection findings questions\n",
    "    inspection_keywords = ['found', 'issues', 'problems', 'condition', 'findings', 'defects', 'damage']\n",
    "    if any(keyword in question.lower() for keyword in inspection_keywords):\n",
    "        return \"rag_analysis\"\n",
    "    \n",
    "    # PRIORITY 4: Everything else ends\n",
    "    return END\n",
    "\n",
    "def rag_analysis_node(state: AgentState):\n",
    "    \"\"\"Smart RAG analysis - handles both findings and complex budget questions\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # Check if this is a complex budget/prioritization question\n",
    "    complex_budget_keywords = ['prioritize', 'priority', 'most important', 'urgent', 'critical']\n",
    "    cost_keywords = ['cost', 'price', 'estimate', 'budget', 'expensive', 'cheap', 'money', 'dollar', '$']\n",
    "    \n",
    "    has_budget_context = any(keyword in question.lower() for keyword in cost_keywords)\n",
    "    has_prioritization = any(keyword in question.lower() for keyword in complex_budget_keywords)\n",
    "    \n",
    "    if has_budget_context and has_prioritization:\n",
    "        # Complex budget question - provide enhanced analysis with cost context\n",
    "        enhanced_question = f\"\"\"Based on the inspection findings, {question}\n",
    "        \n",
    "        Please analyze the inspection report to:\n",
    "        1. Identify all issues and repairs needed\n",
    "        2. Assess the urgency/safety level of each issue  \n",
    "        3. Suggest prioritization based on the budget mentioned\n",
    "        4. Recommend which repairs to address first within the budget constraints\n",
    "        \n",
    "        Focus on safety-critical issues first, then major structural problems, then cosmetic improvements.\"\"\"\n",
    "        \n",
    "        rag_response = baseline_rag_chain.invoke(enhanced_question)\n",
    "        return {\"messages\": [AIMessage(content=f\"**Budget Prioritization Analysis:**\\n\\n{rag_response}\")]}\n",
    "    else:\n",
    "        # Standard inspection findings question\n",
    "        rag_response = baseline_rag_chain.invoke(question)\n",
    "        return {\"messages\": [AIMessage(content=f\"**Inspection Analysis:**\\n\\n{rag_response}\")]}\n",
    "\n",
    "# Build simplified graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_node(\"rag_analysis\", rag_analysis_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "workflow.add_edge(\"rag_analysis\", END)\n",
    "\n",
    "agent = workflow.compile()\n",
    "print(\"‚úÖ Enhanced Agent ready with intelligent tool routing:\")\n",
    "print(\"  üîß Cost questions: Automatic tool sequencing (repair_types ‚Üí cost_estimate)\")\n",
    "print(\"  üè† Inspection questions: RAG analysis\") \n",
    "print(\"  üåê General questions: Web search fallback\")\n",
    "agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setting up 3 retrieval techniques...\n",
      "  ‚úÖ Baseline retriever (from Cell 3)\n",
      "  üîÑ Creating Multi-Query retriever...\n",
      "  üîÑ Creating Parent Document retriever...\n",
      "‚úÖ Created retrievers:\n",
      "  ‚Ä¢ Baseline (Naive) - Basic vector similarity search\n",
      "  ‚Ä¢ Multi-Query - LLM-generated query variations\n",
      "  ‚Ä¢ Parent-Document - Small-to-big retrieval strategy\n",
      "\n",
      "‚úÖ Created 3 RAG chains for comparison:\n",
      "  ‚Ä¢ Baseline\n",
      "  ‚Ä¢ Multi-Query\n",
      "  ‚Ä¢ Parent-Document\n",
      "\n",
      "üß™ Quick test of retrieval techniques:\n",
      "Question: 'What electrical issues were found?'\n",
      "  ‚Ä¢ Baseline: 5 docs - Emergency Lighting systems, Appliances, Tenant Improvements, Energy Efficiency, and any related\n",
      "Equi...\n",
      "  ‚Ä¢ Multi-Query: 6 docs - Emergency Lighting systems, Appliances, Tenant Improvements, Energy Efficiency, and any related\n",
      "Equi...\n",
      "  ‚Ä¢ Parent-Document: 2 docs - 1/16/2021\n",
      "4319 Dixie Canyon Ave, Unit 2,Sherman Oaks,CA\n",
      "¬©Copyright 2018 All Rights Reserved, Unautho...\n",
      "\n",
      "üéØ Ready for performance comparison and evaluation!\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "print(\"Setting up 3 retrieval techniques...\")\n",
    "\n",
    "# 1. Baseline/Naive Retriever (already created in Cell 3)\n",
    "print(\"  Baseline retriever (from Cell 3)\")\n",
    "\n",
    "# 2. Multi-Query Retriever (query expansion with LLM)\n",
    "print(\"  Creating Multi-Query retriever...\")\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=baseline_retriever, \n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# 3. Parent Document Retriever (small-to-big strategy)\n",
    "print(\"  üîÑ Creating Parent Document retriever...\")\n",
    "\n",
    "# Create new vector store for parent docs\n",
    "from qdrant_client import models\n",
    "\n",
    "client_parent = QdrantClient(\":memory:\")\n",
    "client_parent.create_collection(\n",
    "    collection_name=\"parent_documents\",\n",
    "    vectors_config=models.VectorParams(size=embedding_dim, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "parent_vectorstore = QdrantVectorStore(\n",
    "    client=client_parent,\n",
    "    collection_name=\"parent_documents\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Create parent document retriever with smaller child chunks\n",
    "store = InMemoryStore()\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=parent_vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    k=5  # Number of child chunks to retrieve\n",
    ")\n",
    "\n",
    "# Add documents to parent retriever\n",
    "parent_document_retriever.add_documents(inspection_docs, ids=None)\n",
    "\n",
    "print(\" Created retrievers:\")\n",
    "print(\"  ‚Ä¢ Baseline (Naive)\")\n",
    "print(\"  ‚Ä¢ Multi-Query\") \n",
    "print(\"  ‚Ä¢ Parent-Document\")\n",
    "\n",
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Create RAG chains for comparison\n",
    "def create_rag_chain(retriever, name):\n",
    "    \"\"\"Create a RAG chain for a given retriever\"\"\"\n",
    "    return (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "# Store all 3 chains for comparison\n",
    "advanced_chains = {\n",
    "    \"Baseline\": create_rag_chain(baseline_retriever, \"baseline\"),\n",
    "    \"Multi-Query\": create_rag_chain(multi_query_retriever, \"multi_query\"), \n",
    "    \"Parent-Document\": create_rag_chain(parent_document_retriever, \"parent_doc\")\n",
    "}\n",
    "\n",
    "print(f\"\\n Created {len(advanced_chains)} RAG chains for comparison:\")\n",
    "for name in advanced_chains.keys():\n",
    "    print(f\"  ‚Ä¢ {name}\")\n",
    "\n",
    "# Test each retriever with a sample question\n",
    "print(f\"\\n Quick test of retrieval techniques:\")\n",
    "test_question = \"What electrical issues were found?\"\n",
    "\n",
    "print(f\"Question: '{test_question}'\")\n",
    "for name, retriever in [\n",
    "    (\"Baseline\", baseline_retriever),\n",
    "    (\"Multi-Query\", multi_query_retriever), \n",
    "    (\"Parent-Document\", parent_document_retriever)\n",
    "]:\n",
    "    try:\n",
    "        docs = retriever.invoke(test_question)\n",
    "        doc_count = len(docs)\n",
    "        preview = docs[0].page_content[:100] + \"...\" if docs else \"No documents\"\n",
    "        print(f\"  ‚Ä¢ {name}: {doc_count} docs - {preview}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚Ä¢ {name}: Error - {str(e)[:50]}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setting up RAGAS evaluation components...\n",
      "‚úÖ RAGAS components ready:\n",
      "  ‚Ä¢ Evaluator LLM: GPT-4o-mini with 360s timeout\n",
      "  ‚Ä¢ Metrics: Faithfulness, Answer Relevancy, Context Precision, Context Recall\n",
      "  ‚Ä¢ Ready for comprehensive evaluation of 3 retrieval techniques\n",
      "\n",
      "üß™ Quick verification of retrieval setup:\n",
      "Question: 'What electrical issues were found?'\n",
      "  ‚úÖ Baseline: Retrieved 5 documents\n",
      "  ‚úÖ Multi-Query: Retrieved 7 documents\n",
      "  ‚úÖ Parent-Document: Retrieved 2 documents\n",
      "\n",
      "üéØ Ready for comprehensive RAGAS evaluation in Cell 12!\n"
     ]
    }
   ],
   "source": [
    "# RAGAS Setup (Streamlined for 3-Technique Pipeline)\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas import evaluate, RunConfig\n",
    "from ragas.metrics import context_recall, faithfulness, answer_relevancy, context_precision\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "# Core RAGAS components (used by Cell 12)\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\", temperature=0))\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "\n",
    "test_question = \"What electrical issues were found?\"\n",
    "\n",
    "print(f\"Question: '{test_question}'\")\n",
    "for name, retriever in [(\"Baseline\", baseline_retriever), (\"Multi-Query\", multi_query_retriever), (\"Parent-Document\", parent_document_retriever)]:\n",
    "    try:\n",
    "        docs = retriever.invoke(test_question)\n",
    "        print(f\"  ‚úÖ {name}: Retrieved {len(docs)} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå {name}: Error - {str(e)[:50]}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setting up Enhanced Synthetic Dataset Generation...\n",
      "  üîÑ Generating inspection-focused synthetic questions from document content...\n",
      "     Using evaluation documents from data/inspection-reports/\n",
      "‚úÖ Generated 8 inspection-focused questions\n",
      "\n",
      "üìã Generated Inspection Questions:\n",
      "  1. What HVAC issues were identified during the inspection?\n",
      "  2. Are there any electrical problems that need to be addressed?\n",
      "  3. What plumbing repairs are necessary, particularly regarding the dishwasher leak?\n",
      "  4. How urgent are the repairs needed for the deck safety concerns?\n",
      "  ... and 4 more questions\n",
      "\n",
      "üéØ Dataset ready for RAGAS evaluation in Cell 11!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Synthetic Dataset Generation for Inspection-Focused Questions\n",
    "print(\"üîß Setting up Enhanced Synthetic Dataset Generation...\")\n",
    "\n",
    "# Create inspection-focused synthetic questions directly\n",
    "# This approach is more reliable than TestsetGenerator for inspection documents\n",
    "print(\"  üîÑ Generating inspection-focused synthetic questions from document content...\")\n",
    "\n",
    "def generate_inspection_questions_from_docs(docs, num_questions=8):\n",
    "    \"\"\"Generate inspection-focused questions using LLM directly\"\"\"\n",
    "    \n",
    "    # Sample relevant document chunks\n",
    "    sample_chunks = []\n",
    "    seen_content = set()\n",
    "    \n",
    "    for doc in docs[:100]:  # Use more docs for variety\n",
    "        content = doc.page_content.strip()\n",
    "        if len(content) > 100 and content not in seen_content:\n",
    "            # Filter for inspection-relevant content\n",
    "            inspection_keywords = ['electrical', 'plumbing', 'hvac', 'roof', 'structural', \n",
    "                                 'defect', 'damage', 'repair', 'condition', 'system', \n",
    "                                 'safety', 'issue', 'problem', 'recommend']\n",
    "            if any(keyword in content.lower() for keyword in inspection_keywords):\n",
    "                sample_chunks.append(content)\n",
    "                seen_content.add(content)\n",
    "                if len(sample_chunks) >= 12:  # Get diverse content\n",
    "                    break\n",
    "    \n",
    "    if not sample_chunks:\n",
    "        print(\"  ‚ö†Ô∏è No suitable inspection content found, using fallback\")\n",
    "        return None\n",
    "    \n",
    "    # Generate questions using LLM\n",
    "    question_prompt = \"\"\"Based on the following inspection report content, generate {num_questions} simple questions that a homebuyer would ask about the property inspection findings.\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "\n",
    "- Generate simple questions about HVAC, electrical, plumbing, roof, flooring, and safety issues\n",
    "- DO NOT ask about property addresses, inspector names, dates, or metadata\n",
    "- Ask about conditions, repairs needed, age, and safety concerns\n",
    "- SOME EXAMPLES:\n",
    "    - What electrical issues were found?\n",
    "    - Are there any plumbing problems? \n",
    "    - What repairs are most urgent?\n",
    "    - What are the most important safety concerns?\n",
    "    - What are the most important structural issues?\n",
    "    - What are the most important electrical issues?\n",
    "    - What are the most important plumbing issues?\n",
    "    - What are the most important roof issues?\n",
    "    - What are the most important flooring issues?\n",
    "    - What are the most important safety issues?\n",
    "INSPECTION CONTENT:\n",
    "{content}\n",
    "\n",
    "Generate {num_questions} distinct questions in this format:\n",
    "1. [Question]\n",
    "2. [Question]\n",
    "3. [Question]\n",
    "...\n",
    "\n",
    "Questions:\"\"\".format(\n",
    "        num_questions=num_questions,\n",
    "        content=\"\\n\\n---\\n\\n\".join(sample_chunks[:8])  # Use subset to avoid token limits\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        generator_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.4)\n",
    "        response = generator_llm.invoke(question_prompt)\n",
    "        \n",
    "        # Parse questions from response\n",
    "        questions = []\n",
    "        lines = response.content.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line and (line[0].isdigit() or line.startswith('-') or line.startswith('‚Ä¢')):\n",
    "                # Remove numbering and clean up\n",
    "                question = line.split('.', 1)[-1].strip()\n",
    "                if question.endswith('?'):\n",
    "                    questions.append(question)\n",
    "        \n",
    "        return questions[:num_questions] if questions else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Error generating questions: {e}\")\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    # Generate questions from evaluation documents\n",
    "    print(\"     Using evaluation documents from data/inspection-reports/\")\n",
    "    generated_questions = generate_inspection_questions_from_docs(split_eval_docs, 8)\n",
    "    \n",
    "    if generated_questions and len(generated_questions) > 0:\n",
    "        print(f\"‚úÖ Generated {len(generated_questions)} inspection-focused questions\")\n",
    "        \n",
    "        # Create a simple dataset structure compatible with RAGAS\n",
    "        from datasets import Dataset\n",
    "        \n",
    "        synthetic_dataset = Dataset.from_dict({\n",
    "            'user_input': generated_questions,\n",
    "            'reference': ['Based on inspection report analysis'] * len(generated_questions),\n",
    "            'reference_contexts': [['Inspection document content']] * len(generated_questions)\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nüìã Generated Inspection Questions:\")\n",
    "        for i, q in enumerate(generated_questions[:4], 1):\n",
    "            print(f\"  {i}. {q}\")\n",
    "        \n",
    "        if len(generated_questions) > 4:\n",
    "            print(f\"  ... and {len(generated_questions) - 4} more questions\")\n",
    "        \n",
    "        print(f\"\\nüéØ Dataset ready for RAGAS evaluation in Cell 11!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Could not generate questions, will use fallback in evaluation\")\n",
    "        synthetic_dataset = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error in synthetic generation: {e}\")\n",
    "    print(\"  Will use fallback questions in evaluation\")\n",
    "    synthetic_dataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAGAS evaluation on 3 optimized retrieval techniques...\n",
      "Using 6 questions from synthetic dataset\n",
      "Created 3 optimized retrievers\n",
      "Evaluating Baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a29fc907ff8400bbd05f002ec18b1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Overall Score: 0.636\n",
      "Evaluating Multi-Query...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a004ceec8244e3ab6eb933c4307e853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Overall Score: 0.688\n",
      "Evaluating Parent-Document...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8d395fa65c4dd0a6767297fb6bf9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Overall Score: 0.559\n",
      "\n",
      "RAGAS Evaluation Results:\n",
      "============================================================\n",
      "1st Multi-Query:\n",
      "    Overall: 0.688\n",
      "    Context Recall: 0.619\n",
      "    Faithfulness: 0.843\n",
      "    Answer Relevancy: 0.601\n",
      "\n",
      "2nd Baseline:\n",
      "    Overall: 0.636\n",
      "    Context Recall: 0.500\n",
      "    Faithfulness: 0.800\n",
      "    Answer Relevancy: 0.610\n",
      "\n",
      "3rd Parent-Document:\n",
      "    Overall: 0.559\n",
      "    Context Recall: 0.564\n",
      "    Faithfulness: 0.652\n",
      "    Answer Relevancy: 0.461\n",
      "\n",
      "Best Performer: Multi-Query (0.688)\n"
     ]
    }
   ],
   "source": [
    "# Optimized RAGAS Evaluation of 3 Retrieval Techniques\n",
    "\n",
    "print(\"Running RAGAS evaluation on 3 optimized retrieval techniques...\")\n",
    "\n",
    "# Import components\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas import RunConfig, evaluate\n",
    "from ragas.metrics import context_recall, faithfulness, answer_relevancy\n",
    "from datasets import Dataset\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Setup RAGAS components\n",
    "if 'evaluator_llm' not in locals():\n",
    "    evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\", temperature=0))\n",
    "\n",
    "if 'custom_run_config' not in locals():\n",
    "    custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "# Extract questions from synthetic dataset\n",
    "eval_questions = []\n",
    "ground_truths = []\n",
    "\n",
    "if 'synthetic_dataset' in locals() and synthetic_dataset:\n",
    "    try:\n",
    "        df = synthetic_dataset.to_pandas()\n",
    "        \n",
    "        # Try different column names for questions\n",
    "        question_col = None\n",
    "        for col in ['question', 'questions', 'query', 'user_input']:\n",
    "            if col in df.columns:\n",
    "                question_col = col\n",
    "                break\n",
    "        \n",
    "        if question_col:\n",
    "            eval_questions = df[question_col].head(6).tolist()\n",
    "            print(f\"Using {len(eval_questions)} questions from synthetic dataset\")\n",
    "        else:\n",
    "            print(f\"No question column found. Available: {list(df.columns)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing synthetic dataset: {e}\")\n",
    "\n",
    "# Fallback questions if synthetic dataset unavailable\n",
    "if not eval_questions:\n",
    "    eval_questions = [\n",
    "        \"What electrical issues were found?\",\n",
    "        \"Are there any plumbing problems?\", \n",
    "        \"What HVAC defects were identified?\",\n",
    "        \"What structural concerns exist?\",\n",
    "        \"Are there any roofing issues?\",\n",
    "        \"What safety hazards were noted?\"\n",
    "    ]\n",
    "    print(\"Using fallback inspection questions\")\n",
    "\n",
    "# Create ground truth from actual retrieval\n",
    "def create_ground_truth(questions, retriever):\n",
    "    truths = []\n",
    "    for question in questions:\n",
    "        try:\n",
    "            docs = retriever.invoke(question)\n",
    "            if docs:\n",
    "                content = \" \".join([doc.page_content[:200] for doc in docs[:2]])\n",
    "                truths.append(content)\n",
    "            else:\n",
    "                truths.append(\"No relevant findings in inspection report\")\n",
    "        except:\n",
    "            truths.append(\"Unable to determine from inspection report\")\n",
    "    return truths\n",
    "\n",
    "ground_truths = create_ground_truth(eval_questions, baseline_retriever)\n",
    "\n",
    "# Create optimized retrievers\n",
    "optimized_baseline = vector_store.as_retriever(search_kwargs={\"k\": 8})\n",
    "\n",
    "optimized_multi_query = MultiQueryRetriever.from_llm(\n",
    "    retriever=optimized_baseline,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "optimized_parent_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=parent_vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=150),\n",
    "    k=8\n",
    ")\n",
    "\n",
    "retrievers = {\n",
    "    \"Baseline\": optimized_baseline,\n",
    "    \"Multi-Query\": optimized_multi_query,\n",
    "    \"Parent-Document\": optimized_parent_retriever\n",
    "}\n",
    "\n",
    "print(f\"Created {len(retrievers)} optimized retrievers\")\n",
    "\n",
    "# Evaluate retrievers\n",
    "results = {}\n",
    "\n",
    "for retriever_name, retriever in retrievers.items():\n",
    "    print(f\"Evaluating {retriever_name}...\")\n",
    "    \n",
    "    try:\n",
    "        contexts_list = []\n",
    "        answers_list = []\n",
    "        \n",
    "        for question in eval_questions:\n",
    "            retrieved_docs = retriever.invoke(question)\n",
    "            contexts = [doc.page_content for doc in retrieved_docs]\n",
    "            \n",
    "            chain = advanced_chains[\"Baseline\"]\n",
    "            answer = chain.invoke(question)\n",
    "            \n",
    "            contexts_list.append(contexts)\n",
    "            answers_list.append(answer)\n",
    "        \n",
    "        eval_dataset = Dataset.from_dict({\n",
    "            \"question\": eval_questions,\n",
    "            \"answer\": answers_list,\n",
    "            \"contexts\": contexts_list,\n",
    "            \"ground_truth\": ground_truths\n",
    "        })\n",
    "        \n",
    "        result = evaluate(\n",
    "            dataset=eval_dataset,\n",
    "            metrics=[context_recall, faithfulness, answer_relevancy],\n",
    "            llm=evaluator_llm,\n",
    "            run_config=custom_run_config\n",
    "        )\n",
    "        \n",
    "        result_df = result.to_pandas()\n",
    "        context_recall_score = float(result_df[\"context_recall\"].mean()) if \"context_recall\" in result_df.columns else 0.0\n",
    "        faithfulness_score = float(result_df[\"faithfulness\"].mean()) if \"faithfulness\" in result_df.columns else 0.0\n",
    "        answer_relevancy_score = float(result_df[\"answer_relevancy\"].mean()) if \"answer_relevancy\" in result_df.columns else 0.0\n",
    "        \n",
    "        overall_score = (context_recall_score + faithfulness_score + answer_relevancy_score) / 3\n",
    "        \n",
    "        results[retriever_name] = {\n",
    "            \"context_recall\": context_recall_score,\n",
    "            \"faithfulness\": faithfulness_score,\n",
    "            \"answer_relevancy\": answer_relevancy_score,\n",
    "            \"overall\": overall_score\n",
    "        }\n",
    "        \n",
    "        print(f\"  Overall Score: {overall_score:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        results[retriever_name] = {\n",
    "            \"context_recall\": 0.0, \"faithfulness\": 0.0,\n",
    "            \"answer_relevancy\": 0.0, \"overall\": 0.0\n",
    "        }\n",
    "\n",
    "# Display results\n",
    "print(\"\\nRAGAS Evaluation Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if results:\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1]['overall'], reverse=True)\n",
    "    \n",
    "    for i, (name, scores) in enumerate(sorted_results, 1):\n",
    "        rank = [\"1st\", \"2nd\", \"3rd\"][i-1] if i <= 3 else f\"{i}th\"\n",
    "        print(f\"{rank} {name}:\")\n",
    "        print(f\"    Overall: {scores['overall']:.3f}\")\n",
    "        print(f\"    Context Recall: {scores['context_recall']:.3f}\")\n",
    "        print(f\"    Faithfulness: {scores['faithfulness']:.3f}\")\n",
    "        print(f\"    Answer Relevancy: {scores['answer_relevancy']:.3f}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"Best Performer: {sorted_results[0][0]} ({sorted_results[0][1]['overall']:.3f})\")\n",
    "    \n",
    "    # Store for future reference\n",
    "    ragas_results = results\n",
    "\n",
    "else:\n",
    "    print(\"No results available\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
